{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0l1xzaCYtrA8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment as hungarian\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score, adjusted_mutual_info_score\n",
        "\n",
        "cluster_nmi = normalized_mutual_info_score\n",
        "def cluster_acc(y_true, y_pred):\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "  \n",
        "    # ind = sklearn.utils.linear_assignment_.linear_assignment(w.max() - w)\n",
        "    # row_ind, col_ind = linear_assignment(w.max() - w)\n",
        "    row_ind, col_ind = hungarian(w.max() - w)\n",
        "    return sum([w[i, j] for i, j in zip(row_ind, col_ind)]) * 1.0 / y_pred.size\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = float(self.sum) / self.count\n",
        "\n",
        "class Timer(object):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.interval = 0\n",
        "        self.time = time.time()\n",
        "\n",
        "    def value(self):\n",
        "        return time.time() - self.time\n",
        "        \n",
        "    def tic(self):\n",
        "        self.time = time.time()\n",
        "        \n",
        "    def toc(self):\n",
        "        self.interval = time.time() - self.time\n",
        "        self.time = time.time()\n",
        "        return self.interval\n",
        "\n",
        "class Confusion(object):\n",
        "    \"\"\"\n",
        "    column of confusion matrix: predicted index\n",
        "    row of confusion matrix: target index\n",
        "    \"\"\"\n",
        "    def __init__(self, k, normalized = False):\n",
        "        super(Confusion, self).__init__()\n",
        "        self.k = k\n",
        "        self.conf = torch.LongTensor(k,k)\n",
        "        self.normalized = normalized\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.conf.fill_(0)\n",
        "        self.gt_n_cluster = None\n",
        "\n",
        "    def cuda(self):\n",
        "        self.conf = self.conf.cuda()\n",
        "\n",
        "    def add(self, output, target):\n",
        "        output = output.squeeze()\n",
        "        target = target.squeeze()\n",
        "        assert output.size(0) == target.size(0), \\\n",
        "                'number of targets and outputs do not match'\n",
        "        if output.ndimension()>1: #it is the raw probabilities over classes\n",
        "            assert output.size(1) == self.conf.size(0), \\\n",
        "                'number of outputs does not match size of confusion matrix'\n",
        "        \n",
        "            _,pred = output.max(1) #find the predicted class\n",
        "        else: #it is already the predicted class\n",
        "            pred = output\n",
        "        indices = (target*self.conf.stride(0) + pred.squeeze_().type_as(target)).type_as(self.conf)\n",
        "        ones = torch.ones(1).type_as(self.conf).expand(indices.size(0))\n",
        "        self._conf_flat = self.conf.view(-1)\n",
        "        self._conf_flat.index_add_(0, indices, ones)\n",
        "\n",
        "    def classIoU(self,ignore_last=False):\n",
        "        confusion_tensor = self.conf\n",
        "        if ignore_last:\n",
        "            confusion_tensor = self.conf.narrow(0,0,self.k-1).narrow(1,0,self.k-1)\n",
        "        union = confusion_tensor.sum(0).view(-1) + confusion_tensor.sum(1).view(-1) - confusion_tensor.diag().view(-1)\n",
        "        acc = confusion_tensor.diag().float().view(-1).div(union.float()+1)\n",
        "        return acc\n",
        "        \n",
        "    def recall(self,clsId):\n",
        "        i = clsId\n",
        "        TP = self.conf[i,i].sum().item()\n",
        "        TPuFN = self.conf[i,:].sum().item()\n",
        "        if TPuFN==0:\n",
        "            return 0\n",
        "        return float(TP)/TPuFN\n",
        "        \n",
        "    def precision(self,clsId):\n",
        "        i = clsId\n",
        "        TP = self.conf[i,i].sum().item()\n",
        "        TPuFP = self.conf[:,i].sum().item()\n",
        "        if TPuFP==0:\n",
        "            return 0\n",
        "        return float(TP)/TPuFP      \n",
        "        \n",
        "    def f1score(self,clsId):\n",
        "        r = self.recall(clsId)\n",
        "        p = self.precision(clsId)\n",
        "        print(\"classID:{}, precision:{:.4f}, recall:{:.4f}\".format(clsId, p, r))\n",
        "        if (p+r)==0:\n",
        "            return 0\n",
        "        return 2*float(p*r)/(p+r)\n",
        "        \n",
        "    def acc(self):\n",
        "        TP = self.conf.diag().sum().item()\n",
        "        total = self.conf.sum().item()\n",
        "        if total==0:\n",
        "            return 0\n",
        "        return float(TP)/total\n",
        "        \n",
        "    def optimal_assignment(self,gt_n_cluster=None,assign=None):\n",
        "        if assign is None:\n",
        "            mat = -self.conf.cpu().numpy() #hungaian finds the minimum cost\n",
        "            r,assign = hungarian(mat)\n",
        "        self.conf = self.conf[:,assign]\n",
        "        self.gt_n_cluster = gt_n_cluster\n",
        "        return assign\n",
        "        \n",
        "    def show(self,width=6,row_labels=None,column_labels=None):\n",
        "        print(\"Confusion Matrix:\")\n",
        "        conf = self.conf\n",
        "        rows = self.gt_n_cluster or conf.size(0)\n",
        "        cols = conf.size(1)\n",
        "        if column_labels is not None:\n",
        "            print((\"%\" + str(width) + \"s\") % '', end='')\n",
        "            for c in column_labels:\n",
        "                print((\"%\" + str(width) + \"s\") % c, end='')\n",
        "            print('')\n",
        "        for i in range(0,rows):\n",
        "            if row_labels is not None:\n",
        "                print((\"%\" + str(width) + \"s|\") % row_labels[i], end='')\n",
        "            for j in range(0,cols):\n",
        "                print((\"%\"+str(width)+\".d\")%conf[i,j],end='')\n",
        "            print('')\n",
        "        \n",
        "    def conf2label(self):\n",
        "        conf=self.conf\n",
        "        gt_classes_count=conf.sum(1).squeeze()\n",
        "        n_sample = gt_classes_count.sum().item()\n",
        "        gt_label = torch.zeros(n_sample)\n",
        "        pred_label = torch.zeros(n_sample)\n",
        "        cur_idx = 0\n",
        "        for c in range(conf.size(0)):\n",
        "            if gt_classes_count[c]>0:\n",
        "                gt_label[cur_idx:cur_idx+gt_classes_count[c]].fill_(c)\n",
        "            for p in range(conf.size(1)):\n",
        "                if conf[c][p]>0:\n",
        "                    pred_label[cur_idx:cur_idx+conf[c][p]].fill_(p)\n",
        "                cur_idx = cur_idx + conf[c][p];\n",
        "        return gt_label,pred_label\n",
        "    \n",
        "    def clusterscores(self):\n",
        "        target,pred = self.conf2label()\n",
        "        NMI = normalized_mutual_info_score(target,pred)\n",
        "        ARI = adjusted_rand_score(target,pred)\n",
        "        AMI = adjusted_mutual_info_score(target,pred)\n",
        "        return {'NMI':NMI,'ARI':ARI,'AMI':AMI} \n",
        "    def print_(self):\n",
        "        for i in range(self.k):\n",
        "            for j in range(self.k):\n",
        "                print(self.conf[i,j],end=' ')\n",
        "            print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf=Confusion(5)  \n",
        "conf.add(torch.tensor([0]*110+[1]*110+[2]*110+[3]*110),torch.tensor([0]*110+[0]*110+[0]*110+[0]*110))\n",
        "conf.optimal_assignment(5)\n",
        "acc_model = conf.acc()                                  \n",
        "conf.clusterscores()  \n",
        "conf.print_()                                    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwqwgOwkt31H",
        "outputId": "2fc4f5f6-476e-41bf-84ce-0a22f3213f9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(110) tensor(0) tensor(110) tensor(110) tensor(110) \n",
            "\n",
            "tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) \n",
            "\n",
            "tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) \n",
            "\n",
            "tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) \n",
            "\n",
            "tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}